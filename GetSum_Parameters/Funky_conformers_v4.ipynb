{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f023fae9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33169b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:36:57.978011Z",
     "start_time": "2022-09-15T22:36:56.850143Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from morfeus import BuriedVolume\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from matplotlib import rcParams\n",
    "import os, re\n",
    "import get_sum_conformers_v3 as geetum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc3509",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "* This script pulls from an atom numbers spreadsheet as well as a directory with folders for each ligand that contain all of the log files for each. \n",
    "\n",
    "* See example Atom numbers spreadsheet and filesystem for more details\n",
    "\n",
    "* Input is only required in Part 2 and Part 3. All other cells can be run without user input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2eb87",
   "metadata": {},
   "source": [
    "# Determine What Ligands Will Be Parameterized and Where to Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227eef0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:36:57.981100Z",
     "start_time": "2022-09-15T22:36:57.979175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input either 'All Ligands' or 'Specific Ligands' \n",
    "pull_parameters_for = 'All Ligands' \n",
    "\n",
    "# If 'Specific Ligands', input a list of ligand IDs\n",
    "Specific_Ligand_IDs = ['8',  '27']\n",
    "\n",
    "# Populate variable excel_name with the desired name for the parameters file (e.g. \"myparameters.xlsx\") \n",
    "# and filepath where you wnt  (e.g. \"~/Desktop/Parameters/\")\n",
    "excel_name = 'Test.xlsx'\n",
    "excel_filepath = 'Parameter_spreadsheets/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab81250",
   "metadata": {},
   "source": [
    "# Load Atom Numbers and log filenames and filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f686d",
   "metadata": {},
   "source": [
    "This notebook is set up to pull parameters for bisphosphine ligands that have been optimized with PdCl2 and single-point calculations have been run on the optimized structure with and without palladium. \n",
    "\n",
    "Then create an excel spreadsheet that contains the names of the log files and the atom numbers both with and without Palladium. These will be read in as Pd_anum_df and NoPd_anum_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef14108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:36:58.529055Z",
     "start_time": "2022-09-15T22:36:57.982852Z"
    }
   },
   "outputs": [],
   "source": [
    "# New path for ligand folders\n",
    "Ligands_path = 'DFT_files_atom_nums/Ligand_Calcs/'\n",
    "\n",
    "# Filepaths for atom numbers spreadsheets\n",
    "Pd_path = 'DFT_files_atom_nums/SPE_Pd/' #File path for single-point .log files with PdCl2\n",
    "NoPd_path = 'DFT_files_atom_nums/NoPd/' #File path for single-point .log files without PdCl2\n",
    "OPT_path = 'DFT_files_atom_nums/OPT/'   #File path for single-point .log files of geometry optimizations\n",
    "\n",
    "\n",
    "# load in atom numbers spreadsheet\n",
    "num_columns_Pd = 17   #input the number of columns in the Pd atom number spreadsheet (should not change)\n",
    "num_columns_NoPd = 15    #input the number of columns in the NoPd atom number spreadsheet (should not change)\n",
    "Pd_anum_df = pd.read_excel('DFT_files_atom_nums/Atom_numbers_4_2022.xlsx', sheet_name=\"Pd\", usecols=list(range(0,(num_columns_Pd))))\n",
    "NoPd_anum_df = pd.read_excel('DFT_files_atom_nums/Atom_numbers_4_2022.xlsx', sheet_name=\"No_Pd\", usecols=list(range(0,(num_columns_NoPd))))\n",
    "# dictionary: key = Ligand ID, value = Ligand Name\n",
    "ligname_dict = dict(zip(list(Pd_anum_df['Ligand ID']), list(Pd_anum_df.Ligand)))\n",
    "Pd_anum_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25cfc4",
   "metadata": {},
   "source": [
    "# Generate dictionary with all log names for all conformers\n",
    "\n",
    "\n",
    "\n",
    "NO USER INPUT REQUIRED BEYOND THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdba8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:36:58.653953Z",
     "start_time": "2022-09-15T22:36:58.530341Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Master_Conf_Dict\n",
    "# key = ligand id (str)\n",
    "# value = sub dictionary\n",
    "# sub dictionary:\n",
    "# key = conformer number (int)\n",
    "# value = [opt_name, SPE_name, SPE_NoPd_name]\n",
    "Master_Conf_Dict = {}\n",
    "\n",
    "# Iterate through ligand folders\n",
    "ligand_folders = os.listdir(Ligands_path)\n",
    "\n",
    "# removes items in filenames in the Ligands_path directory that are not folders (e.g. hidden files like .DS_Store)\n",
    "for item in ligand_folders:\n",
    "    try:\n",
    "        os.listdir(Ligands_path + item)\n",
    "    except:\n",
    "        ligand_folders.remove(item)\n",
    "\n",
    "# Takes each folder name and populates with the ligand ID (string element of folder name before '_') and \n",
    "# The names of all of the log folders that should be in there. This is done by recognizing the base name (i.e. Segphos)\n",
    "# and the number of coformers, and generating 'Segphos_#', 'Segphos_#_SPE', and 'Segphos_#_SPE_NoPd' for each conformer\n",
    "# It is critical that each folder is named '<Ligand ID>_<Ligand Name>' and \n",
    "# each log file is named <ligand name>_<conformer number>_<.log, _SPE.log, _SPE_NoPd.log for OPT and single points repsectively>.\n",
    "for folder in ligand_folders:\n",
    "    ID_i = int(folder.split('_')[0]) # Ligand ID\n",
    "    sub_dict = {} \n",
    "    conformers = [] # will populate with conformer names (e.g. Segphos_1, Segphos_2, etc.)\n",
    "    \n",
    "    # find unique conformer names\n",
    "    for file in os.listdir(Ligands_path + folder):\n",
    "        # appends only the optimization files to the conformers list (e.g. Segphos_1, Segphos_2, etc.)\n",
    "        if re.search('_[12345].log', file) and file[:-4] not in conformers:\n",
    "            conformers.append(file[:-4])\n",
    "\n",
    "    # add conformer number (e.g. 1) and conformer log names \n",
    "    # (e.g. 'Segphos_1.log', 'Segphos_1_SPE.log', and 'Segphos_1_SPE_NoPd.log')\n",
    "    # note that the base name is defined by the optimization log file of conformer 1.\n",
    "    # This means if conformer 1 is named 'Segphos_1.log', the base name will be Segphos.\n",
    "    # However if the base name has something in it like 'tight', that will be included in the base name for every \n",
    "    # Conformer\n",
    "    for conf_num in range(1,len(conformers)+1): # not zero-indexed\n",
    "        conf_name = conformers[0][:-2] + '_' + str(conf_num)# name of conformer (e.g. 'Segphos_1')\n",
    "        conf_opt, conf_SPE, conf_NoPd = conf_name, conf_name + '_SPE', conf_name + '_SPE_NoPd'\n",
    "        sub_dict[conf_num] = [conf_opt, conf_SPE, conf_NoPd]\n",
    "    Master_Conf_Dict[ID_i] = sub_dict\n",
    "\n",
    "# Sort Master_Conf_Dict in order of ascending ligand IDs\n",
    "Master_Conf_Dict = dict(sorted(Master_Conf_Dict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af049cfd",
   "metadata": {},
   "source": [
    "## Clean-Up Dictionary with All log Names\n",
    "\n",
    "* Removes ligands from Master_Conf_Dict if any of their respective log names are not real files\n",
    "\n",
    "(e.g. if 'Segphos_3.log' is not a real file and the optimization for comformer 3 is actually named 'Segphos_3_tight.log' then an alert will be raised and all coformers of Segphos will be removed from the dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae12724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:36:58.676829Z",
     "start_time": "2022-09-15T22:36:58.655708Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Problem_Ligands_Dict = {} # Problem ligands: key = ligand_ID, value = list of non-existant ligand names\n",
    "        \n",
    "# iterate through all of the ligand folders\n",
    "for lig_folder in ligand_folders:\n",
    "    problem_files = []\n",
    "    \n",
    "    # record the ligand ID\n",
    "    lig_ID = int(lig_folder.split('_')[0] ) \n",
    "    \n",
    "    # make a list of all the files in the given folder\n",
    "    actual_files = os.listdir(Ligands_path + lig_folder)\n",
    "    \n",
    "    # make a list of dictionary files (OPTs, SPEs, and NoPd_SPEs)\n",
    "    dict_files = [file + '.log' for sublist in Master_Conf_Dict[lig_ID].values() for file in sublist]\n",
    "    \n",
    "\n",
    "    # check if every file in the dictionary list is in the actual file list\n",
    "    for file in dict_files:\n",
    "        if file not in actual_files:\n",
    "            problem_files.append(file)\n",
    "    \n",
    "    # updates Problem_Ligands_Dict with ligands that have naming issues\n",
    "    if len(problem_files) > 0:\n",
    "        Problem_Ligands_Dict[lig_ID] = problem_files \n",
    "        \n",
    "# print out the ligands that have issues\n",
    "for ligand, files in Problem_Ligands_Dict.items():\n",
    "    print('--------------------------------')\n",
    "    print('Problem with ligand {}:'.format(ligand))\n",
    "    for file in files:\n",
    "        print(file)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "# Remove ligands with naming issues from Master_Conf_Dict\n",
    "for i in Problem_Ligands_Dict:\n",
    "    del Master_Conf_Dict[i]      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c22a0",
   "metadata": {},
   "source": [
    "## Check that each folder has the correct ligand ID\n",
    "\n",
    "* This cell takes the ligand ID from Master_Conf_Dict and makes sure that the SPE, NoPd, and OPT lognames for the lowest energy conformer and recorded in the atom numbers spreadsheet actually exists in that folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd94c91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:36:59.285319Z",
     "start_time": "2022-09-15T22:36:58.758479Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder_ids = [folder.split('_')[0] for folder in ligand_folders]\n",
    "folder_dict = dict(zip(folder_ids, ligand_folders))\n",
    "\n",
    "folders_with_issues = []\n",
    "for ID, conf_dict_i in Master_Conf_Dict.items():\n",
    "    ID = str(ID)\n",
    "    folder_name_i = folder_dict[ID]\n",
    "    correct_SPE = list(Pd_anum_df[Pd_anum_df['Ligand ID'] == int(ID)]['log_name'])[0] + '.log'\n",
    "    correct_NoPd_SPE = list(NoPd_anum_df[NoPd_anum_df['Ligand ID'] == int(ID)]['log_name'])[0] + '.log'\n",
    "    correct_OPT = list(NoPd_anum_df[NoPd_anum_df['Ligand ID'] == int(ID)]['opt_log_name'])[0] + '.log'\n",
    "    correct_LOGs = [correct_NoPd_SPE, correct_OPT, correct_SPE]\n",
    "    \n",
    "    try:\n",
    "        real_files = os.listdir(Ligands_path + folder_name_i)\n",
    "        for correct_filename in correct_LOGs:\n",
    "            if correct_filename not in real_files:\n",
    "                if folder_name_i not in folders_with_issues:\n",
    "                    folders_with_issues.append(folder_name_i)\n",
    "                print('{} {}.\\n{} does not exist in the folder.\\n'.format(ID, folder_name_i, correct_filename))\n",
    "    except:\n",
    "        print('Problem with {}. This folder does not exist\\n\\n\\n'.format(folder_name))\n",
    "        \n",
    "\n",
    "print('{} folders have naming inconsistencies'.format(len(folders_with_issues)))\n",
    "print(folders_with_issues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ed896",
   "metadata": {},
   "source": [
    "## Creates an atom number dataframe with a row for every conformer of every ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c307542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:37:15.955700Z",
     "start_time": "2022-09-15T22:36:59.286492Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ligand_Filepath_Dict key = ID (int) Value = Filepath pointing to ligand log and com files.\n",
    "Ligand_Filepath_Dict = {}\n",
    "for folder in ligand_folders:\n",
    "    ID = int(folder.split('_')[0])\n",
    "    filepath = Ligands_path + folder + '/'\n",
    "    Ligand_Filepath_Dict[ID] = filepath\n",
    "Ligand_Filepath_Dict = dict(sorted(Ligand_Filepath_Dict.items()))\n",
    "    \n",
    "\n",
    "# Create a dataframes Conf_Pd_anum_df and Conf_NoPd_anum_df (w/ and w/o PdCl2) \n",
    "# with a row for each ligand conformer. An additional row is added for conformer number (1-5)\n",
    "Conf_Pd_anum_df = pd.DataFrame(columns=list(Pd_anum_df.columns) + ['Conf_Number'])\n",
    "Conf_NoPd_anum_df = pd.DataFrame(columns=list(NoPd_anum_df.columns) + ['Conf_Number'])\n",
    "\n",
    "\n",
    "for ID_i, conformers in Master_Conf_Dict.items():\n",
    "    for conf in conformers:\n",
    "        # get the row values for the Pd_anum_df (i.e. Ligand ID, Ligand name, atom numbers)\n",
    "        Pd_anum_row = Pd_anum_df[Pd_anum_df['Ligand ID'] == int(ID_i)].values[0].tolist()\n",
    "        NoPd_anum_row = NoPd_anum_df[Pd_anum_df['Ligand ID'] == int(ID_i)].values[0].tolist()\n",
    "        # omit the log name of the lowest energy conformer that is stored in Pd_anum_df\n",
    "        Pd_anum_row = Pd_anum_row[:-1]\n",
    "        # omit the lowest energy conformer NoPd_SPE and OPT log names that are stored in Pd_anum_df\n",
    "        NoPd_anum_row = NoPd_anum_row[:-2]\n",
    "        \n",
    "        # update the row from the atom_numbers_spreadsheet to include the the log names for each conformer \n",
    "        # as well as the conformer numbers\n",
    "        [conf_OPT, conf_SPE, conf_NoPd] = Master_Conf_Dict[ID_i][conf]\n",
    "        #Add filepath info\n",
    "        filepath = Ligand_Filepath_Dict[ID_i]\n",
    "        conf_OPT, conf_SPE, conf_NoPd = filepath + conf_OPT, filepath + conf_SPE, filepath + conf_NoPd\n",
    "        Pd_anum_row = Pd_anum_row + [conf_SPE, conf]\n",
    "        NoPd_anum_row = NoPd_anum_row + [conf_NoPd, conf_OPT, conf]\n",
    "\n",
    "        # add the lists as new rows to both the Conf_Pd_anum_df and Conf_NoPd_anum_df\n",
    "        Conf_Pd_anum_df.loc[len(Conf_Pd_anum_df.index)] = Pd_anum_row\n",
    "        Conf_NoPd_anum_df.loc[len(Conf_NoPd_anum_df.index)] = NoPd_anum_row\n",
    "\n",
    "# Updates Ligand ID and conformer number to strings\n",
    "Conf_Pd_anum_df = Conf_Pd_anum_df.astype({'Ligand ID': str, 'Conf_Number': str})\n",
    "Conf_NoPd_anum_df = Conf_NoPd_anum_df.astype({'Ligand ID': str, 'Conf_Number': str})\n",
    "\n",
    "# Updates the Conf_Pd_anum_df and Conf_NoPd_anum_df so that the ligand ID is updated \n",
    "# To include the conformer (i.e. for ligand 8 that has two conformers there is a row '8:1' and '8:2')\n",
    "Conf_Pd_anum_df['Ligand ID'] = Conf_Pd_anum_df['Ligand ID'] + ':' + Conf_Pd_anum_df['Conf_Number']\n",
    "Conf_NoPd_anum_df['Ligand ID'] = Conf_NoPd_anum_df['Ligand ID'] + ':' + Conf_NoPd_anum_df['Conf_Number']\n",
    "\n",
    "\n",
    "display(Conf_Pd_anum_df, Conf_NoPd_anum_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a5afe",
   "metadata": {},
   "source": [
    "# Define Functions For Pulling Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25974fb6",
   "metadata": {},
   "source": [
    "## Define Functions to Pull Burried Volume\n",
    "\n",
    "* To Do: Double-Check to ensure that the quadrants and octants are assigned correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365aa735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:37:15.965707Z",
     "start_time": "2022-09-15T22:37:15.957061Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This function iterates over a dataframe with the following columns:\n",
    "#1. Ligand ID, 2. Ligand, 3-13 are atom numbers, and 14 is the name of the log file (without .log) \n",
    "def Vbur_one_radius(radius, dataframe, plot_images=False, export_parameters=True):\n",
    "    bv_dataframe = pd.DataFrame(columns=['Ligand ID', 'Ligand','Vbur%', 'NE', 'NW', 'SE', 'SW'])\n",
    "    for index, row in dataframe.iterrows():\n",
    "        enantiomer = False\n",
    "        if str(row['Ligand ID'])[-2:] == '_1':\n",
    "            enantiomer = True\n",
    "        try:\n",
    "            log_file = row['log_name']\n",
    "            streams, errors = geetum.get_outstreams(log_file)\n",
    "            log_coordinates = geetum.get_geom(streams)\n",
    "            elements = np.array([log_coordinates[i][0] for i in range(len(log_coordinates))])\n",
    "            coordinates = np.array([np.array(log_coordinates[i][1:]) for i in range(len(log_coordinates))])\n",
    "            metal_anum = row['Pd']          #Pd atom number (1-indexed)\n",
    "\n",
    "            bv = BuriedVolume(elements, coordinates, metal_anum,\n",
    "                      excluded_atoms=[row['Cl1'], row['Cl2']],  #Phosphine atom numbers (1-indexed)\n",
    "                      z_axis_atoms=[row['P1'],row['P2']],     #Chloride atom numbers (1-indexed)\n",
    "                      xz_plane_atoms=[row['P2']],      #Phosphine oriented east\n",
    "                     include_hs=True,\n",
    "                      radius=radius)           # \n",
    "            bv.octant_analysis()  \n",
    "            bv_quads = bv.quadrants['percent_buried_volume']\n",
    "            bv_octs = bv.octants['percent_buried_volume']\n",
    "            if enantiomer == False:\n",
    "                row_i = {'Ligand ID': row['Ligand ID'],'Ligand': row['Ligand'],'Vbur%': 100*bv.fraction_buried_volume,\n",
    "                         'NE': bv_quads[1], 'NW': bv_quads[2], 'SW':bv_quads[3], 'SE': bv_quads[4],\n",
    "                        'NE_octant': bv_octs[0], 'NW_octant': bv_octs[1], 'SW_octant': bv_octs[2], 'SE_octant': bv_octs[3]}\n",
    "            if enantiomer == True:\n",
    "                row_i = {'Ligand ID': row['Ligand ID'],'Ligand': row['Ligand'],'Vbur%': 100*bv.fraction_buried_volume,\n",
    "                         'SE': bv_quads[1], 'SW': bv_quads[2], 'NW':bv_quads[3], 'NE': bv_quads[4],\n",
    "                        'SE_octant': bv_octs[0], 'SW_octant': bv_octs[1], 'NW_octant': bv_octs[2], 'NE_octant': bv_octs[3]}\n",
    "            if export_parameters==True:\n",
    "                bv_dataframe = bv_dataframe.append(row_i, ignore_index=True)\n",
    "            if plot_images==True:\n",
    "                print('Steric map for ', row['Ligand'], \":\")\n",
    "                bv.plot_steric_map()\n",
    "        except:\n",
    "            print('Unable to acquire Vbur parameters for:', row['Ligand'])\n",
    "    if export_parameters==True:\n",
    "        name_addon = \"_\" + str(radius) + '_Ang'\n",
    "        bv_dataframe.rename(columns={'Vbur%': 'Vbur%'+ name_addon, 'NE': 'NE' + name_addon, 'NW': 'NW' + name_addon,\n",
    "                                     'SE': 'SE'+ name_addon, 'SW':'SW' + name_addon, 'NE_octant': 'NE_octant' + name_addon,\n",
    "                                     'NW_octant': 'NW_octant' + name_addon, 'SW_octant': 'SW_octant' + name_addon,\n",
    "                                    'SE_octant': 'SE_octant' + name_addon,}, inplace=True)\n",
    "        return(bv_dataframe)\n",
    "\n",
    "\n",
    "# This function generates %Vbur (total and quadrants) at defined starting and stopping radius and stepsize\n",
    "# (e.g. from 2.0Å to 4.0Å at 0.5 Å steps) and returns all of them in a single dataframe.\n",
    "def get_Vbur(start_r, end_r, step_size, dataframe, plot_images=False, enantiomer=False):\n",
    "    num_steps = int((end_r-start_r)/step_size + 1)\n",
    "    radii = [start_r + step_size*i for i in range(num_steps)]\n",
    "    df_lst = []\n",
    "    for radius in radii:\n",
    "        df_lst.append(Vbur_one_radius(radius, dataframe, plot_images))\n",
    "    dfmaster = pd.merge(df_lst[0], df_lst[1])\n",
    "    for i in range(2,len(df_lst)):\n",
    "        dfmaster = pd.merge(dfmaster, df_lst[i])\n",
    "    return(dfmaster)\n",
    "\n",
    "def plot_quadrants(radius, dataframe):\n",
    "    Vbur_one_radius(radius, dataframe, plot_images=True, export_parameters=False)\n",
    "\n",
    "#test_vbur = get_Vbur(2, 7, 1, Pd_anum_df[:10]) \n",
    "#test_vbur.head(5)\n",
    "#writer = pd.ExcelWriter('Parameter_spreadsheets/' + 'Vbur_2.xlsx', engine='xlsxwriter')\n",
    "#test_vbur.to_excel(writer, sheet_name= 'Vbur')\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a56ef",
   "metadata": {},
   "source": [
    "## Define Electronics and Bond-Angle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8f658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T22:37:15.972519Z",
     "start_time": "2022-09-15T22:37:15.967264Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bond_vals(dataframe_Pd, dataframe_NoPd):\n",
    "    bondvals_dataframe_Pd = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'SPE_HF_E', 'Symmetry'])#['Ligand ID', 'Ligand', 'SPE_HF_E', 'Symmetry', 'PR1_NBO', 'PR2_NBO', 'PRBack_NBO', 'XR1_NBO', 'XR2_NBO', 'XRBack_NBO', 'P1_NMR', 'X_NMR', 'Homo', 'Lumo', 'dipole', 'P1NBO', 'X_NBO', 'Pd_NBO', 'Cl_1_NBO', 'Cl_2_NBO', 'P1_Pd_bond_occ', 'P1_Pd_bond_eng', 'X_Pd_bond_occ', 'X_Pd_bond_eng', 'P1_Pd_antibond_occ', 'P1_Pd_antibond_eng', 'X_Pd_antibond_occ', 'X_Pd_antibond_eng', 'Pd_LP_1_occ', 'Pd_LP_1_eng', 'Pd_LP_2_occ', 'Pd_LP_2_eng', 'Pd_LP_3_occ', 'Pd_LP_3_eng', 'Pd_LP_4_occ', 'Pd_LP_4_eng', 'P1_R1_bond_occ', 'P1_R1_bond_eng', 'X_R3_bond_occ', 'X_R3_bond_eng', 'P1_R2_bond_occ', 'P1_R2_bond_eng', 'X_R4_bond_occ', 'X_R4_bond_eng', 'P1_Rback_bond_occ', 'P1_Rback_bond_eng', 'X_Rback_bond_occ', 'X_Rback_bond_eng', 'P1_R1_antibond_occ', 'P1_R1_antibond_eng', 'X_R3_antibond_occ', 'X_R3_antibond_eng', 'P1_R2_antibond_occ', 'P1_R2_antibond_eng', 'X_R4_antibond_occ', 'X_R4_antibond_eng', 'P1_Rback_antibond_occ', 'P1_Rback_antibond_eng', 'X_Rback_antibond_occ', 'X_Rback_antibond_eng'])\n",
    "    bondvals_dataframe_NoPd = pd.DataFrame(columns=['Ligand ID'])#['Ligand ID', 'NoPd_PR1_NBO', 'NoPd_PR2_NBO', 'NoPd_PRBack_NBO', 'NoPd_XR1_NBO', 'NoPd_XR2_NBO', 'NoPd_XRBack_NBO','NoPd_Homo', 'NoPd_Lumo', 'NoPd_dipole', 'NoPd_P1NBO', 'NoPd_X_NBO', 'NoPd_P1_NMR', 'NoPd_X_NMR', 'NoPd_aniso_P1_NMR', 'NoPd_aniso_X_NMR', 'NoPd_P1_LP_occ', 'NoPd_P1_LP_eng', 'NoPd_X_LP_occ', 'NoPd_X_LP_eng', 'NoPd_P1_R1_bond_occ', 'NoPd_P1_R1_bond_eng', 'NoPd_P1_R2_bond_occ', 'NoPd_P1_R2_bond_eng', 'NoPd_P1_Rback_bond_occ', 'NoPd_P1_Rback_bond_eng', 'NoPd_X_R3_bond_occ', 'NoPd_X_R3_bond_eng', 'NoPd_X_R4_bond_occ', 'NoPd_X_R4_bond_eng', 'NoPd_X_Rback_bond_occ', 'NoPd_X_Rback_bond_eng', 'NoPd_P1_R1_antibond_occ', 'NoPd_P1_R1_antibond_eng', 'NoPd_P1_R2_antibond_occ', 'NoPd_P1_R2_antibond_eng', 'NoPd_P1_Rback_antibond_occ', 'NoPd_P1_Rback_antibond_eng', 'NoPd_X_R3_antibond_occ', 'NoPd_X_R3_antibond_eng', 'NoPd_X_R4_antibond_occ', 'NoPd_X_R4_antibond_eng', 'NoPd_X_Rback_antibond_occ', 'NoPd_X_Rback_antibond_eng', 'NoPd_LP_P1_s', 'NoPd_LP_X_s'])\n",
    "    \n",
    "    for index, row in dataframe_Pd.iterrows():\n",
    "        try:\n",
    "            str_row = row.astype(str)\n",
    "            atom_num_dict, SPE_dict, measurements_dict = geetum.get_SPE_Pd(str_row['log_name'], [str_row['P1'], str_row['P2']], [str_row['Pd'], str_row['Cl1'], str_row['Cl2']], [str_row['R1'], str_row['R2'], str_row['R3'], str_row['R4']], [str_row['RBack1'], str_row['RBack2']])            \n",
    "            row_head = {'Ligand ID': row['Ligand ID'], 'Ligand': row['Ligand'], 'Symmetry': row['Symmetry']}\n",
    "            row_i = {**row_head,**SPE_dict, **measurements_dict}\n",
    "            bondvals_dataframe_Pd = bondvals_dataframe_Pd.append(row_i, ignore_index=True)\n",
    "        except:\n",
    "            print('Unable to acquire bond/angle parameters (w/ PdCl2) for:', row['Ligand'])    \n",
    "    for index, row in dataframe_NoPd.iterrows():\n",
    "        try:\n",
    "            str_row = row.astype(str)\n",
    "            SPE_NoPd_dict = geetum.get_SPE_NoPd(str_row['log_name'], [str_row['P1'], str_row['P2']], [str_row['R1'], str_row['R2'], str_row['R3'], str_row['R4']], [str_row['RBack1'], str_row['RBack2']])\n",
    "            polarizability_dict = geetum.get_polarizability(str_row['opt_log_name'])\n",
    "            row_head = {'Ligand ID': row['Ligand ID']}\n",
    "            row_i = {**row_head,**SPE_NoPd_dict,**polarizability_dict}\n",
    "            bondvals_dataframe_NoPd = bondvals_dataframe_NoPd.append(row_i, ignore_index=True)\n",
    "        except:\n",
    "            print('Unable to acquire bond/angle parameters (w/o PdCl2) for:', row['Ligand'])\n",
    "    \n",
    "    bondvals_dataframe_Pd['Ligand ID'] = bondvals_dataframe_Pd['Ligand ID'].astype(str)\n",
    "    bondvals_dataframe_NoPd['Ligand ID'] = bondvals_dataframe_NoPd['Ligand ID'].astype(str)\n",
    "    bondvals_dataframe = pd.merge(bondvals_dataframe_Pd, bondvals_dataframe_NoPd, on='Ligand ID')\n",
    "    return(bondvals_dataframe)\n",
    "\n",
    "##Below code is for testing this cell \n",
    "\n",
    "#test_bondvals = bond_vals(Conf_Pd_anum_df2, Conf_NoPd_anum_df2)\n",
    "#test_bondvals.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52b9b",
   "metadata": {},
   "source": [
    "# Renumber Atoms Based On X/P–Cback Occupancy\n",
    "\n",
    "* Input only required above the hashed line\n",
    "\n",
    "* Specify whether you want to pull parameters for the full library of just for a list of specific ligands\n",
    "\n",
    "TO DO: \n",
    "\n",
    "* Check that this is working correctly by spot checking the parameter values vs the Phosphorus numbering\n",
    "\n",
    "* Add a cell to ensure that the atom numbers are the same for every conformer of a given compound \n",
    "\n",
    "* Check by hand that each ligand of a given backbone has the same P1/P2 designation\n",
    "\n",
    "* Remove print statements from get_sum.py script\n",
    "\n",
    "* Excel Hack: copy a column of ligand IDs in excel, paste them into a print(\"\"\" \"\"\".split()) statement and copy the resultant printed list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929aae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T23:00:04.888142Z",
     "start_time": "2022-09-15T22:37:15.973755Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if pull_parameters_for == 'Specific Ligands':\n",
    "    Conf_Pd_anum_df2 = Conf_Pd_anum_df.loc[Conf_Pd_anum_df.apply(lambda row: row['Ligand ID'].split(':')[0] in Specific_Ligand_IDs, axis=1)]\n",
    "    Conf_NoPd_anum_df2 = Conf_NoPd_anum_df.loc[Conf_NoPd_anum_df.apply(lambda row: row['Ligand ID'].split(':')[0] in Specific_Ligand_IDs, axis=1)]\n",
    "\n",
    "if pull_parameters_for == 'All Ligands':\n",
    "    Conf_Pd_anum_df2, Conf_NoPd_anum_df2 = Conf_Pd_anum_df, Conf_NoPd_anum_df\n",
    "##########################################################################################################\n",
    "\n",
    "Pd_anum_df2 = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'P1', 'P2', 'Pd', 'Cl1', 'Cl2', 'R1', 'R2',\n",
    "       'R3', 'R4', 'RBack1', 'RBack2', 'Symmetry', 'Chiral', 'log_name'])\n",
    "NoPd_anum_df2 = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'P1', 'P2', 'R1', 'R2', 'R3', 'R4',\n",
    "       'RBack1', 'RBack2', 'Symmetry', 'Chiral', 'log_name', 'opt_log_name'])\n",
    "bond_vals_df0 = bond_vals(Conf_Pd_anum_df2, Conf_NoPd_anum_df2)\n",
    "bond_vals_df0 = bond_vals_df0.set_index('Ligand ID')\n",
    "working_ligands = list(bond_vals_df0.index)   # This returns a list of ligand IDs for ligands that work in bond_vals function  \n",
    "\n",
    "for index, row in Conf_Pd_anum_df2.iterrows():     #Pd block\n",
    "    lig_ID = str(row['Ligand ID'])\n",
    "    P1_Rback_occ = bond_vals_df0.loc[lig_ID,'P1_RBack1_bond_occ']\n",
    "    P2_Rback_occ = bond_vals_df0.loc[lig_ID,'P2_RBack2_bond_occ']\n",
    "    if lig_ID not in working_ligands:\n",
    "        print(lig_ID, ' was not added to new atom number list dued to failed parameterization!')\n",
    "    else:\n",
    "        if row['Renumber'] == False:\n",
    "            #Pd_anum block 44\n",
    "            row_Pd = row.drop('Renumber')\n",
    "            Pd_anum_df2.loc[len(Pd_anum_df2.index)] = list(row_Pd[:-1])\n",
    "        else:\n",
    "            if P2_Rback_occ > P1_Rback_occ:\n",
    "                #Pd_anum block \n",
    "                Ligand_ID = row['Ligand ID']\n",
    "                Ligand = row['Ligand']\n",
    "                P1 = row['P2']\n",
    "                P2 = row['P1']\n",
    "                Pd = row['Pd']\n",
    "                Cl1 = row['Cl2']\n",
    "                Cl2 = row['Cl1']\n",
    "                R1 = row['R4']\n",
    "                R2 = row['R3']\n",
    "                R3 = row['R2']\n",
    "                R4 = row['R1']\n",
    "                RBack1 = row['RBack2']\n",
    "                RBack2 = row['RBack1']\n",
    "                Symmetry = row['Symmetry']\n",
    "                Chiral = row['Chiral']\n",
    "                log_name = row['log_name']\n",
    "                new_row = [Ligand_ID, Ligand,  P1, P2, Pd, Cl1, Cl2, R1, R2, R3, R4, RBack1, RBack2, Symmetry, Chiral, log_name]\n",
    "                Pd_anum_df2.loc[len(Pd_anum_df2.index)] = new_row\n",
    "            else:\n",
    "                #Pd_anum block  \n",
    "                row_Pd = row.drop('Renumber')\n",
    "                Pd_anum_df2.loc[len(Pd_anum_df2.index)] = list(row_Pd[:-1])                \n",
    "                \n",
    "                \n",
    "for index, row in Conf_NoPd_anum_df2.iterrows():     #NoPd block\n",
    "    lig_ID = str(row['Ligand ID'])\n",
    "    P1_Rback_occ = bond_vals_df0.loc[lig_ID,'P1_RBack1_bond_occ']\n",
    "    P2_Rback_occ = bond_vals_df0.loc[lig_ID,'P2_RBack2_bond_occ']\n",
    "    if lig_ID not in working_ligands:\n",
    "        print(lig_ID, ' was not added to new atom number list dued to failed parameterization!')\n",
    "    else:\n",
    "        if row['Renumber'] == False:\n",
    "            row_NoPd = row.drop('Renumber')\n",
    "            NoPd_anum_df2.loc[len(NoPd_anum_df2.index)] = list(row_NoPd[:-1])\n",
    "        else:\n",
    "            if P2_Rback_occ > P1_Rback_occ:\n",
    "                #NoPd_anum block \n",
    "                Ligand_ID = row['Ligand ID']\n",
    "                Ligand = row['Ligand']\n",
    "                P1 = row['P2']\n",
    "                P2 = row['P1']\n",
    "                R1 = row['R4']\n",
    "                R2 = row['R3']\n",
    "                R3 = row['R2']\n",
    "                R4 = row['R1']\n",
    "                RBack1 = row['RBack2']\n",
    "                RBack2 = row['RBack1']\n",
    "                Symmetry = row['Symmetry']\n",
    "                Chiral = row['Chiral']\n",
    "                log_name = row['log_name']\n",
    "                opt_log_name = row['opt_log_name']\n",
    "                new_row = [Ligand_ID, Ligand, P1, P2, R1, R2, R3, R4, RBack1, RBack2, Symmetry,  Chiral, log_name, opt_log_name]\n",
    "                NoPd_anum_df2.loc[len(NoPd_anum_df2.index)] = new_row\n",
    "            else:\n",
    "                #NoPd_anum block \n",
    "                row_NoPd = row.drop('Renumber')\n",
    "                NoPd_anum_df2.loc[len(NoPd_anum_df2.index)] = list(row_NoPd[:-1])\n",
    "    \n",
    "\n",
    "                \n",
    "# display(Pd_anum_df2, NoPd_anum_df2) # display not defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46bca95",
   "metadata": {},
   "source": [
    "## Check that every conformer for each ligand has the same P1/P2 designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff682ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T23:00:20.241062Z",
     "start_time": "2022-09-15T23:00:04.889754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a list of all the ligand IDs for which parameters were pulled.\n",
    "IDs_Pulled = []\n",
    "for i in Pd_anum_df2['Ligand ID'].to_list():\n",
    "    ID = i.split(':')[0]\n",
    "    if ID not in IDs_Pulled:\n",
    "        IDs_Pulled.append(ID)\n",
    "        \n",
    "# Check that the atom numbers are the same for every row of a given ID\n",
    "inconsistent_P1_P2_ligands = [] \n",
    "for ID in IDs_Pulled:\n",
    "    # Select all conformers for a given ID\n",
    "    Sub_df_Pd = Pd_anum_df2.loc[Pd_anum_df2.apply(lambda row: ID == row['Ligand ID'].split(':')[0], axis = 1)]\n",
    "    Sub_df_NoPd = NoPd_anum_df2.loc[NoPd_anum_df2.apply(lambda row: ID == row['Ligand ID'].split(':')[0], axis = 1)]\n",
    "    \n",
    "    # make a list of atom number columns for Pd and NoPd dataframes\n",
    "    Pd_atom_number_columns, NoPd_atom_number_columns = Pd_anum_df2.columns[2:-3], NoPd_anum_df2.columns[2:-4]\n",
    "    \n",
    "    # Check that the atom numbers in each column are the same\n",
    "    unique_anumbers_Pd = [len(pd.unique(Sub_df_Pd[atom])) for atom in Pd_atom_number_columns]\n",
    "    unique_anumbers_NoPd = [len(pd.unique(Sub_df_NoPd[atom])) for atom in NoPd_atom_number_columns]\n",
    "    \n",
    "    inconsistent_Pd = True in (unique_anumb > 1 for unique_anumb in unique_anumbers_Pd)\n",
    "    inconsistent_NoPd = True in (unique_anumb > 1 for unique_anumb in unique_anumbers_NoPd)\n",
    "    \n",
    "    # Print warning that atom numbers are inconsistent across conformers for a given ligand\n",
    "    if inconsistent_Pd or inconsistent_NoPd:\n",
    "        inconsistent_P1_P2_ligands.append(ID)\n",
    "\n",
    "print('P1/P2 convention is inconsistent for the following ligands:\\n')\n",
    "for ID in inconsistent_P1_P2_ligands:\n",
    "    print('{} (ID {})'.format(ligname_dict[int(ID)], ID))\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab70f9",
   "metadata": {},
   "source": [
    "# Generate Atom Number Spreadsheets w/ Enantiomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6af1fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T23:01:05.872536Z",
     "start_time": "2022-09-15T23:00:20.243065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Renumbering is not required for Vbur parameters. Instead we simply switch the lables on North and South octants\n",
    "# and quadrants (e.g. NW_4Å becomes SW_4Å)\n",
    "\n",
    "# Pd_anum_df3 and NoPd_anum_df3 just have extra rows with the same atom numbers\n",
    "# Pd_anum_df4 and NoPd_anum_df4 have updated atom numbers where R2/3 and R3/4 are switched.\n",
    "\n",
    "Pd_anum_df3 = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'P1', 'P2', 'Pd', 'Cl1', 'Cl2', 'R1', 'R2',\n",
    "       'R3', 'R4', 'RBack1', 'RBack2', 'Symmetry', 'log_name'])\n",
    "NoPd_anum_df3 = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'P1', 'P2', 'R1', 'R2', 'R3', 'R4',\n",
    "       'RBack1', 'RBack2', 'Symmetry', 'log_name',  'opt_log_name'])\n",
    "Pd_anum_df4 = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'P1', 'P2', 'Pd', 'Cl1', 'Cl2', 'R1', 'R2',\n",
    "       'R3', 'R4', 'RBack1', 'RBack2', 'Symmetry', 'log_name'])\n",
    "NoPd_anum_df4 = pd.DataFrame(columns=['Ligand ID', 'Ligand', 'P1', 'P2', 'R1', 'R2', 'R3', 'R4',\n",
    "       'RBack1', 'RBack2','Symmetry', 'log_name', 'opt_log_name'])\n",
    "\n",
    "##### Pd_anum_df3 and NoPd_anum_df3 #####\n",
    "# iterates through Pd_anum_df2 and adds rows for both base ligand and enantiomer (e.g. R_Segphos and R_Segphos_ENANT)\n",
    "# Pd block \n",
    "for index, row in Pd_anum_df2.iterrows():   \n",
    "    if row['Chiral'] == True:\n",
    "        new_row = list(row)\n",
    "        del new_row[-2] # Removes Chiral = T/F column from the row.\n",
    "        Pd_anum_df3.loc[len(Pd_anum_df3.index)] = new_row #Adds row for calculated enantiomer\n",
    "        new_row[0] = str(new_row[0]) + '_1'\n",
    "        new_row[1] = new_row[1] + '_ENANT'\n",
    "        Pd_anum_df3.loc[len(Pd_anum_df3.index)] = new_row #Adds row for new enantiomer (with same atom numbers for now)\n",
    "    else:\n",
    "        new_row = list(row)\n",
    "        del new_row[-2]\n",
    "        Pd_anum_df3.loc[len(Pd_anum_df3.index)] = new_row\n",
    "        \n",
    "# NoPd block         \n",
    "for index, row in NoPd_anum_df2.iterrows():   \n",
    "    if row['Chiral'] == True:\n",
    "        new_row = list(row)\n",
    "        del new_row[-3]\n",
    "        NoPd_anum_df3.loc[len(NoPd_anum_df3.index)] = new_row #Adds row for calculated enantiomer\n",
    "        new_row[0] = str(new_row[0]) + '_1'\n",
    "        new_row[1] = new_row[1] + '_ENANT'\n",
    "        NoPd_anum_df3.loc[len(NoPd_anum_df3.index)] = new_row #Adds row for new enantiomer (with same atom numbers for now)\n",
    "    else:\n",
    "        new_row = list(row)\n",
    "        del new_row[-3]\n",
    "        NoPd_anum_df3.loc[len(NoPd_anum_df3.index)] = new_row\n",
    "\n",
    "##### Pd_anum_df4 and NoPd_anum_df4 #####\n",
    "for index, row in Pd_anum_df3.iterrows():  #Pd Block\n",
    "    if str(row['Ligand ID'])[-2:] == '_1':\n",
    "        Ligand_ID = row['Ligand ID']\n",
    "        Ligand = row['Ligand']\n",
    "        P1 = row['P1']\n",
    "        P2 = row['P2']\n",
    "        Pd = row['Pd']\n",
    "        Cl1 = row['Cl1']\n",
    "        Cl2 = row['Cl2']\n",
    "        R1 = row['R2']\n",
    "        R2 = row['R1']\n",
    "        R3 = row['R4']\n",
    "        R4 = row['R3']\n",
    "        RBack1 = row['RBack1']\n",
    "        RBack2 = row['RBack2']\n",
    "        Symmetry = row['Symmetry']\n",
    "        log_name = row['log_name']\n",
    "        new_row = [Ligand_ID, Ligand, P1, P2, Pd, Cl1, Cl2, R1, R2, R3, R4, RBack1, RBack2, Symmetry, log_name]\n",
    "        Pd_anum_df4.loc[len(Pd_anum_df4.index)] = new_row\n",
    "    else:\n",
    "        new_row = list(row)\n",
    "        Pd_anum_df4.loc[len(Pd_anum_df4.index)] = new_row\n",
    "        \n",
    "        \n",
    "for index, row in NoPd_anum_df3.iterrows():  #NoPd Block\n",
    "    if str(row['Ligand ID'])[-2:] == '_1':\n",
    "        Ligand_ID = row['Ligand ID']\n",
    "        Ligand = row['Ligand']\n",
    "        P1 = row['P1']\n",
    "        P2 = row['P2']\n",
    "        R1 = row['R2']\n",
    "        R2 = row['R1']\n",
    "        R3 = row['R4']\n",
    "        R4 = row['R3']\n",
    "        RBack1 = row['RBack1']\n",
    "        RBack2 = row['RBack2']\n",
    "        Symmetry = row['Symmetry']\n",
    "        log_name = row['log_name']\n",
    "        opt_log_name = row['opt_log_name']\n",
    "        new_row = [Ligand_ID, Ligand, P1, P2, R1, R2, R3, R4, RBack1, RBack2, Symmetry, log_name, opt_log_name]\n",
    "        NoPd_anum_df4.loc[len(NoPd_anum_df4.index)] = new_row\n",
    "    else:\n",
    "        new_row = list(row)\n",
    "        NoPd_anum_df4.loc[len(NoPd_anum_df4.index)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb1a20",
   "metadata": {},
   "source": [
    "# Run Functions to Pull Parameters (Enantiomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0018e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:11:08.253442Z",
     "start_time": "2022-09-15T23:01:05.874100Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Vbur_df = get_Vbur(3, 7, 1.0, Pd_anum_df3[:])      # This must be run on Pd_anum_df3\n",
    "print('\\n\\nDone Running Vbur collection')\n",
    "bond_vals_df = bond_vals(Pd_anum_df4[:], NoPd_anum_df4[:])\n",
    "print('\\n\\nDone Running bondvals collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db671e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T20:28:38.459144Z",
     "start_time": "2022-05-10T20:28:38.456108Z"
    }
   },
   "source": [
    "## Combine Vbur, and BondVals into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae3639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:11:11.374959Z",
     "start_time": "2022-09-16T01:11:08.254903Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Vbur_df['Ligand ID'] = Vbur_df['Ligand ID'].astype(str)\n",
    "df_all_params = pd.merge(bond_vals_df, Vbur_df)\n",
    "\n",
    "errorcount = 0\n",
    "\n",
    "# Removes any ligands that have any errors in the parameter acquisition\n",
    "ligands_with_errors = [] # List of Ligand IDs with Errors\n",
    "for index, row in df_all_params.iterrows():\n",
    "    row_lc = [i.lower() for i in row if type(i) == str] # lower case row\n",
    "    if 'error' in row_lc:\n",
    "        ID_i = row['Ligand ID'].split(':')[0]\n",
    "        print('Error detected in {}'.format(row['Ligand ID']))\n",
    "        if ID_i not in ligands_with_errors:\n",
    "            ligands_with_errors.append(ID_i)\n",
    "\n",
    "# Remove ligands where at least one conformer has an error\n",
    "for index, row in df_all_params.iterrows():\n",
    "    ID_i = row['Ligand ID'].split(':')[0]\n",
    "    if ID_i in ligands_with_errors:\n",
    "        df_all_params.drop(index, inplace=True)            \n",
    "        \n",
    "print('The following ligands were removed because they contain one or more errors:\\n')\n",
    "for ID in ligands_with_errors:\n",
    "    print('{} ({})'.format(ligname_dict[int(ID)], ID))\n",
    "        \n",
    "df_all_params[df_all_params.columns[4:]]= df_all_params[df_all_params.columns[4:]].astype(float)\n",
    "\n",
    "# #generate SPE_G: HF energy from single point\n",
    "df_all_params['SPE_G'] = df_all_params.apply(lambda row: float(row.SPE_HF_E) + float(row.G) - float(row.OPT_HF_E), axis=1)\n",
    "df_all_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45d396",
   "metadata": {},
   "source": [
    "Create Conformer dictionaries\n",
    "\n",
    "* Generates one dictionary for base ligands and one for enantiomers (Enant_Conf_Dict, Base_Conf_Dict)\n",
    "* Each key is a ligand ID (without enantiomer info) and each value is a list of the specific IDs for all conformers of the ligand within the all_params dataframe. (includes conformer and enantiomer info, e.g. ['8:1_1', '8:2_1', ..]). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a433cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:11:11.810428Z",
     "start_time": "2022-09-16T01:11:11.375877Z"
    }
   },
   "outputs": [],
   "source": [
    "# All_Base/Enant_Conf: list of all full ids (e.g. '516:1' from the base/enantiomer ligands)\n",
    "All_Base_Conf = [ID for ID in df_all_params['Ligand ID'] if ID[-2:] != '_1']\n",
    "All_Enant_Conf = [ID for ID in df_all_params['Ligand ID'] if ID[-2:] == '_1']\n",
    "\n",
    "# Iterates through both lists and creates Unique_Base_IDs and Unique_Enant_IDs (e.g. '8', instead of '8:1', '8:2', ...)\n",
    "Unique_Base_IDs = list(set([ID.split(':')[0] for ID in All_Base_Conf]))\n",
    "Unique_Enant_IDs = list(set([ID.split(':')[0] for ID in All_Enant_Conf])) # do not include '_1' ending\n",
    "\n",
    "# Create Enant/Base_Conf_Dict:\n",
    "# Base_Conf_Dict: key = ID (e.g. '8'), value = ID of each conformer (e.g. ['8:1', '8:2', ..])\n",
    "# Enant_Conf_Dict: key = ID (e.g. '8'), value = ID of each conformer (e.g. ['8:1_1', '8:2_1', ..])\n",
    "Enant_Conf_Dict, Base_Conf_Dict = {}, {}\n",
    "\n",
    "# Iterate through Unique_Base_IDs. For ID in Unique_Base_IDs: individual_confs = [] for conf in All_Base_Conf: if ID in conf append id to individual_confs\n",
    "for ID in Unique_Base_IDs:\n",
    "    individual_confs = []\n",
    "    for conf in All_Base_Conf:\n",
    "        if ID == conf.split(':')[0]:\n",
    "            individual_confs.append(conf)\n",
    "    Base_Conf_Dict[ID] = individual_confs\n",
    "    \n",
    "for ID in Unique_Enant_IDs:\n",
    "    individual_confs = []\n",
    "    for conf in All_Enant_Conf:\n",
    "        if ID == conf.split(':')[0]:\n",
    "            individual_confs.append(conf)\n",
    "    Enant_Conf_Dict[ID] = individual_confs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa844c9",
   "metadata": {},
   "source": [
    "# Create A Dataframe with Parameters From the Lowest Energy Conformer for Each Ligand (Raw parameters prior to symmetry adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b1e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:12:09.021702Z",
     "start_time": "2022-09-16T01:11:11.811334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the lowest energy conformer for each ligand \n",
    "Lowconf_All_Params = pd.DataFrame(columns= [i for i in list(df_all_params.columns) if i not in ['SPE_HF_E', 'G', 'OPT_HF_E', 'SPE_G', 'E_Rel']] )\n",
    "\n",
    "\n",
    "# Lowconf_Params for Base Ligands (i.e. not enantiomers)\n",
    "for ID, confs in Base_Conf_Dict.items():\n",
    "    # create a temporary dataframe with all conformers of a given ligand ID\n",
    "    temp_df = df_all_params[df_all_params['Ligand ID'].isin(confs)]    \n",
    "\n",
    "    \n",
    "    # calculate the relative energy within the temporary dataframe\n",
    "    min_energy = min(list(temp_df.SPE_G))\n",
    "    temp_df['E_Rel'] = temp_df.apply(lambda row: 627.5*(row.SPE_G - min_energy), axis=1)\n",
    "\n",
    "    # create the dictionary lowconf_dict\n",
    "    # This dictionary is created for one ligand and contains the parameters for the lowest energy conformer\n",
    "    # {'Ligand ID': 8, 'Ligand': 'DIOP', 'Symmetry': 'C2', 'P1_NMR': '254.1', ...}\n",
    "    lowconf_dict = {'Ligand ID': ID, 'Ligand': ligname_dict[int(ID)], 'Symmetry': temp_df.Symmetry.iloc[0]}\n",
    "    for param in temp_df.columns:\n",
    "        if param not in ['Ligand ID', 'Ligand', 'SPE_HF_E', 'Symmetry', 'G', 'OPT_HF_E', 'SPE_G', 'E_Rel']:\n",
    "        \n",
    "            # This try/except statement is to avoid errors when two conformers have exactly the same relative\n",
    "            # energy, E = 0. We average the degenerate conformer values.\n",
    "            try:\n",
    "                lowconf_i = float(temp_df[temp_df.E_Rel == float(0)][param])\n",
    "            except:\n",
    "                lowconf_i = float(temp_df[temp_df.E_Rel == float(0)][param].mean())\n",
    "            # this adds the parameter value for param to the lowconf_dict\n",
    "            lowconf_dict[param] = lowconf_i\n",
    "            \n",
    "                        \n",
    "    # Add low_conf_dict as a row in Lowconf_All_Params\n",
    "    Lowconf_All_Params.loc[len(Lowconf_All_Params.index)] = lowconf_dict\n",
    "    \n",
    "# Lowconf_Params for ENANT Ligands (i.e. not base parameters)\n",
    "for ID, confs in Enant_Conf_Dict.items():\n",
    "    # create a temporary dataframe where ligand ID == ID\n",
    "    temp_df = df_all_params[df_all_params['Ligand ID'].isin(confs)]\n",
    "    \n",
    "    # calculate the relative energy for each conformer within the temporary dataframe\n",
    "    min_energy = min(list(temp_df.SPE_G))\n",
    "    temp_df['E_Rel'] = temp_df.apply(lambda row: 627.5*(row.SPE_G - min_energy), axis=1)\n",
    "    \n",
    "    # lowconf_dict: {'Ligand ID': 8, 'Ligand': 'DIOP', 'Symmetry': 'C2', 'P1_NMR': '254.1', ...}\n",
    "    lowconf_dict = {'Ligand ID': ID + '_1', 'Ligand': ligname_dict[int(ID)] + '_ENANT', 'Symmetry': temp_df.Symmetry.iloc[0]}\n",
    "    for param in temp_df.columns:\n",
    "        if param not in ['Ligand ID', 'Ligand', 'SPE_HF_E', 'Symmetry', 'G', 'OPT_HF_E', 'SPE_G', 'E_Rel']:\n",
    "\n",
    "            # This try/except statement is to avoid errors when two conformers have exactly the same relative\n",
    "            # energy, E = 0. We average the degenerate conformer values.\n",
    "            try:\n",
    "                lowconf_i = float(temp_df[temp_df.E_Rel == float(0)][param])\n",
    "            except:\n",
    "                lowconf_i = float(temp_df[temp_df.E_Rel == float(0)][param].mean())\n",
    "                \n",
    "            # Add low_conf_dict as a row in Lowconf_All_Params\n",
    "            lowconf_dict[param] = lowconf_i\n",
    "            \n",
    "                        \n",
    "    # Add low_conf_dict as a row in Lowconf_All_Params\n",
    "    Lowconf_All_Params.loc[len(Lowconf_All_Params.index)] = lowconf_dict\n",
    "    \n",
    "Lowconf_All_Params.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748ff0f",
   "metadata": {},
   "source": [
    "# Covert Raw Parameters to Symmetry Adapted Parameters\n",
    "\n",
    "* sym_adapt_lowconf = Low-Energy Conformer Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055c83c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:12:44.651270Z",
     "start_time": "2022-09-16T01:12:09.022572Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#base parameters are the unique parameters w/o symmetry or min/max/avg\n",
    "#(e.g. base parameters would be P1_NMR or P2_NMR, not X_NMR_min or X_NMR_max)\n",
    "base_params = sum(geetum.C1_dict.values(), []) \n",
    "ratio_params = list(geetum.ratio_dict.keys())\n",
    "\n",
    "#Symmetry adapted parameters give min/max/avg for each base parameter\n",
    "#(e.g. P1_NMR_min, P1_NMR_max, and P1_NMR_avg)\n",
    "sym_adapt_params = [[i + '_min', i + '_max', i + '_avg'] for i in base_params]\n",
    "sym_adapt_params = sum(sym_adapt_params, [])\n",
    "\n",
    "#Symmetry adapted ratios give min/max/avg for each ratiometric parameter\n",
    "sym_adapt_ratios = [[i + '_min', i + '_max', i + '_avg'] for i in ratio_params]\n",
    "sym_adapt_ratios = sum(sym_adapt_ratios, [])\n",
    "\n",
    "# Define funciton to symmetry adapt a dataframe of parameters\n",
    "def symmetry_adapt(dataframe):\n",
    "\n",
    "    #sym_adapt_df is a dataframe that will be populated with the symmetry-adapted parameters for each ligand\n",
    "    sym_adapt_df = pd.DataFrame(columns=['Ligand ID', 'Ligand'] + sym_adapt_params + geetum.global_parameters + sym_adapt_ratios)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if 'Error' in list(row):\n",
    "            print('1+ error values were found in ligand {} (ID: {})'.format(row['Ligand'], row['Ligand ID']))\n",
    "            continue\n",
    "        row_i = {'Ligand ID': row['Ligand ID'], 'Ligand': row['Ligand']}\n",
    "        for p in geetum.global_parameters: #this keeps the values for parameters not affected by symmetry (HOMO, Pd_LP_E, etc.)\n",
    "            row_i[p] = row[p]\n",
    "        if row.Symmetry == 'C2':\n",
    "            symmetry_dict = geetum.C2_dict\n",
    "        elif row.Symmetry == 'C2v':\n",
    "            symmetry_dict = geetum.C2v_dict\n",
    "        elif row.Symmetry == 'C1':\n",
    "            symmetry_dict = geetum.C1_dict\n",
    "        else:\n",
    "            print('Error, incorrect symmmetry designation for {} (ID: {})'.format(row['Ligand'], row['Ligand ID']))\n",
    "            continue\n",
    "\n",
    "        for params in symmetry_dict.values():   #This updates parameters that are affected by symmetry to have min/max/avg vals\n",
    "            old_vals = [float(row[p]) for p in params] \n",
    "            #This gives discrete values for symmetry-equivalent groups \n",
    "            for p in params:\n",
    "                p_min, p_max, p_avg = min(old_vals), max(old_vals), statistics.mean(old_vals)\n",
    "                row_i[p + '_min'] = p_min\n",
    "                row_i[p + '_max'] = p_max\n",
    "                row_i[p + '_avg'] = p_avg\n",
    "            \n",
    "        for ratio_i, params in geetum.ratio_dict.items():  #Note: The ratios are optimized for C2 chiral ligands.\n",
    "            ratio_1 = row[params[0][0]]/row[params[0][1]]\n",
    "            ratio_2 = row[params[1][0]]/row[params[1][1]]\n",
    "            ratios = [ratio_1, ratio_2]\n",
    "            ratio_min, ratio_max, ratio_avg = min(ratios), max(ratios), statistics.mean(ratios)\n",
    "            row_i[ratio_i + '_min'] = ratio_min\n",
    "            row_i[ratio_i + '_max'] = ratio_max\n",
    "            row_i[ratio_i + '_avg'] = ratio_avg\n",
    "            \n",
    "        sym_adapt_df = sym_adapt_df.append(row_i, ignore_index=True)\n",
    "\n",
    "    sym_adapt_df.set_index('Ligand ID', inplace=True)\n",
    "    return sym_adapt_df\n",
    "\n",
    "sym_adapt_lowconf = symmetry_adapt(Lowconf_All_Params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40b8d7",
   "metadata": {},
   "source": [
    "# 10. Create All C2v Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e7d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:12:58.402612Z",
     "start_time": "2022-09-16T01:12:44.652269Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_all_c2v(dataframe):\n",
    "#sym_adapt_df is a dataframe that will be populated with the symmetry-adapted parameters for each ligand\n",
    "    C2v_p_names = [[p + '_min', p + '_max', p + '_avg'] for p in list(geetum.C2v_dict.keys())]\n",
    "    C2v_p_names = sum(C2v_p_names,[])\n",
    "    all_c2v_df = pd.DataFrame(columns=['Ligand ID', 'Ligand'] + C2v_p_names + geetum.global_parameters)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if 'Error' in list(row):\n",
    "            print('1+ error values were found in ligand {} (ID: {})'.format(row['Ligand'], row['Ligand ID']))\n",
    "            continue\n",
    "        row_c2v = {'Ligand ID': row['Ligand ID'], 'Ligand': row['Ligand']}\n",
    "        for p in geetum.global_parameters: #this keeps the values for parameters not affected by symmetry\n",
    "            row_c2v[p] = row[p]\n",
    "        C2v_dict = geetum.C2v_dict\n",
    "\n",
    "        for c2v_param, params in C2v_dict.items():   #This updates parameters that are affected by symmetry to have min/max/avg vals \n",
    "            old_vals = [float(row[p]) for p in params] #This gives discrete values for symmetry-equivalent groups \n",
    "            \n",
    "            p_min, p_max, p_avg = min(old_vals), max(old_vals), statistics.mean(old_vals)\n",
    "            row_c2v[c2v_param + '_min'] = p_min\n",
    "            row_c2v[c2v_param + '_max'] = p_max\n",
    "            row_c2v[c2v_param + '_avg'] = p_avg\n",
    "\n",
    "        all_c2v_df = all_c2v_df.append(row_c2v, ignore_index=True)\n",
    "\n",
    "    all_c2v_df.set_index('Ligand ID', inplace=True)\n",
    "    return(all_c2v_df)\n",
    "\n",
    "all_c2v_lowconf = create_all_c2v(Lowconf_All_Params)\n",
    "all_c2v_lowconf.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d54fff",
   "metadata": {},
   "source": [
    "# Export Parameter Spreadsheets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fd54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T01:13:04.412713Z",
     "start_time": "2022-09-16T01:12:58.403501Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(excel_filepath + excel_name, engine='xlsxwriter')\n",
    "all_c2v_lowconf.to_excel(writer, sheet_name='all_C2v')\n",
    "sym_adapt_lowconf.to_excel(writer, sheet_name='Symmetry_Adapted')\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9fbc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "319.167px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
